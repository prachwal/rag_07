# RAG_07 - Multi-provider LLM Application with RAG Support

**Uniwersalna aplikacja LLM z interfejsem web** dla system√≥w RAG
(Retrieval-Augmented Generation), wieloma providerami i bazami wektorowymi.

## üöÄ Funkcjonalno≈õci

- **Multi-provider LLM**: OpenAI, Anthropic, Google, Ollama, OpenRouter, LM Studio
- **Vector Databases**: FAISS, Chroma, Pinecone (extensible architecture)
- **RAG System**: Retrieval-Augmented Generation z automatycznym chunkowaniem
- **Function Calling**: Zaawansowane iteracyjne odpytywanie z LLM
- **Web Interface**:
  - üé® **Streamlit Dashboard** - Interaktywny interfejs u≈ºytkownika
  - üì° **FastAPI Backend** - RESTful API z dokumentacjƒÖ
  - üê≥ **Docker Support** - Production-ready deployment
- **Collection Management**: ZarzƒÖdzanie kolekcjami wektorowymi
- **Command Line Interface**: Intuitive CLI z pe≈ÇnƒÖ obs≈ÇugƒÖ argument√≥w
- **Async Architecture**: Wszystkie operacje asynchroniczne z retry/timeout
- **Advanced Logging System**: JSON structured logging z rotacjƒÖ plik√≥w
- **Configuration Management**: Centralized config z .env i JSON/YAML
- **Type Safety**: Pe≈Çne typowanie z mypy validation
- **Testing**: Comprehensive test suite z mockowaniem API

## üåê Web Interface

### Quick Start
```bash
# Uruchom ca≈Çy system web
./run_web_system.sh

# Lub z Docker
./docker_start.sh
```

### Dostƒôp do aplikacji
- üé® **Streamlit Dashboard**: http://localhost:8501
- üì° **FastAPI Backend**: http://localhost:8000
- üìã **API Documentation**: http://localhost:8000/docs

## üìÅ Struktura projektu (zgodnie z instrukcjami)

```
src/
‚îú‚îÄ‚îÄ main.py                 # Punkt wej≈õciowy (tylko uruchamianie)
‚îú‚îÄ‚îÄ cli.py                  # Obs≈Çuga CLI
‚îú‚îÄ‚îÄ exceptions.py           # Dedykowane wyjƒÖtki
‚îú‚îÄ‚îÄ web/                   # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ api_server.py      # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py   # Streamlit frontend
‚îÇ   ‚îî‚îÄ‚îÄ models.py          # Pydantic models dla API
‚îú‚îÄ‚îÄ services/              # Logika biznesowa
‚îÇ   ‚îî‚îÄ‚îÄ application_service.py
‚îú‚îÄ‚îÄ utils/                 # Funkcje pomocnicze
‚îÇ   ‚îî‚îÄ‚îÄ logger.py          # Structured logging
‚îú‚îÄ‚îÄ models/                # Modele danych
‚îú‚îÄ‚îÄ providers/             # Adaptery dla r√≥≈ºnych API
‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Base interfaces + Factory
‚îÇ   ‚îú‚îÄ‚îÄ llm/              # LLM providers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai_provider.py
‚îÇ   ‚îú‚îÄ‚îÄ vector/           # Vector DB providers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ faiss_provider.py
‚îÇ   ‚îî‚îÄ‚îÄ text/             # Text processors
‚îÇ       ‚îî‚îÄ‚îÄ basic_processor.py
‚îî‚îÄ‚îÄ config/               # Konfiguracje
    ‚îî‚îÄ‚îÄ config_manager.py  # Centralized config management

tests/                    # Testy jednostkowe (CLI + Web)
examples/                 # Przyk≈Çadowe dane (gitignored)
databases/               # Lokalne bazy danych (gitignored)
config/                  # Pliki konfiguracyjne
docker/                  # Docker configuration
```

## üõ† Skonfigurowane narzƒôdzia formatowania

### Python

- **Black** - formatter kodu Python (line-length: 88)
- **isort** - sortowanie import√≥w zgodnie z profilem Black
- **Pylint** - linting kodu Python
- **mypy** - sprawdzanie typ√≥w (opcjonalnie)
- **Ruff** - bardzo szybki linter/formatter

### TypeScript/JavaScript

- **Prettier** - formatter kodu JS/TS
- **ESLint** - linting z regu≈Çami TypeScript
- **TypeScript** - kompilator i sprawdzanie typ√≥w

## ‚ö° Szybki start

### Option 1: Web Interface (Recommended)

```bash
# 1. Setup ≈õrodowiska
./setup.sh

# 2. Konfiguracja API keys
cp .env .env.local
# Edytuj .env.local ze swoimi kluczami API

# 3. Uruchom web system
./run_web_system.sh
```

Dostƒôp do aplikacji:
- **Dashboard**: http://localhost:8501
- **API**: http://localhost:8000
- **Documentation**: http://localhost:8000/docs

### Option 2: Docker Deployment

```bash
# 1. Konfiguracja
cp .env .env.local
# Edytuj .env.local

# 2. Start z Docker
./docker_start.sh

# 3. Production z nginx
./docker_start.sh --production
```

### Option 3: Command Line

```bash
# 1. Setup ≈õrodowiska
./setup.sh

# 2. Konfiguracja
cp .env .env.local
# Dodaj swoje klucze API do .env.local

# 3. Pierwsza komenda
python src/main.py config-status
python src/main.py --help
```

## üìã Dostƒôpne komendy CLI

### Podstawowe operacje

```bash
# Query do LLM (z kontrolƒÖ logowania)
./run.sh query "What is Python?"
./run.sh --log-level WARNING query -p openai -m gpt-4 "Explain machine learning"

# Dodaj tekst do vector store
./run.sh embed "Python is a programming language"
./run.sh --no-log-console embed -p faiss -col documents "Your text here"

# Wyszukaj w vector store
./run.sh search "programming language"
./run.sh --log-level DEBUG search -p faiss -col documents -l 10 "machine learning"

# RAG query (z kontekstem)
./run.sh rag "What is Python used for?"
./run.sh --log-dir /custom/logs rag -p openai -vp faiss -cl 5 "Explain AI"

# Function Calling (zaawansowane)
./run.sh ask-with-tools "What are the main features of this system?" --verbose
./run.sh --log-level ERROR ask-with-tools "Question" --verbose  # Minimize logs
```

### ZarzƒÖdzanie kolekcjami

```bash
# Lista kolekcji
./run.sh list-collections

# Informacje o kolekcji
./run.sh collection-info nazwa_kolekcji

# Automatyczne indeksowanie dokumentacji
./scripts/index_documentation.sh

# Demonstracja mo≈ºliwo≈õci
./scripts/collections_demo.sh
```

### ZarzƒÖdzanie systemem

```bash
# Status konfiguracji
./run.sh config-status

# Lista dostƒôpnych provider√≥w
./run.sh list-providers
./run.sh list-providers --provider-type llm

# Lista dostƒôpnych modeli
./run.sh list-models
./run.sh list-models --provider openai --format table
```

## üìö Dokumentacja zarzƒÖdzania kolekcjami

### Szybki start

```bash
# 1. Sprawd≈∫ status
./run.sh config-status

# 2. Utw√≥rz kolekcjƒô z dokumentami
./run.sh embed --collection docs "$(cat README.md)"

# 3. Przetestuj
./run.sh ask-with-tools "What is this project about?" --verbose
```

### Pe≈Çna dokumentacja

- **[ZarzƒÖdzanie kolekcjami](docs/collections_management.md)** - Kompletny
  przewodnik
- **[Szybki start](docs/quick_start_collections.md)** - Praktyczny przewodnik
- **Demonstracja**: `./scripts/collections_demo.sh` - Interaktywny tutorial

## üß™ Automatyczne formatowanie VS Code

### VS Code Tasks (Ctrl+Shift+P ‚Üí "Tasks: Run Task")

- **Setup Environment** - uruchamia setup.sh
- **Format All** - isort + black
- **Lint (Pylint)** - sprawdzanie kodu
- **Type Check (MyPy)** - sprawdzanie typ√≥w
- **Run Tests** - pytest z coverage
- **Run Application** - uruchamia aplikacjƒô z --help

### Rƒôczne formatowanie

```bash
# Python
source .venv/bin/activate
black src/              # Formatowanie Black
isort src/              # Sortowanie import√≥w
pylint src/             # Linting
mypy src/               # Type checking
pytest                  # Testy

# JavaScript/TypeScript (je≈õli u≈ºywasz)
npm run format          # Formatowanie Prettier
npm run lint            # ESLint z automatycznymi poprawkami
```

## üîß Dodawanie nowych provider√≥w

### 1. LLM Provider

```python
# src/providers/llm/my_provider.py
from providers.base import LLMProvider

class MyProvider(LLMProvider):
    async def initialize(self) -> None:
        # Inicjalizacja

    async def generate_text(self, prompt: str, **kwargs) -> str:
        # Implementacja
```

### 2. Rejestracja w Factory

```python
# Automatyczna rejestracja w providers/base.py
# Dodaj import w _register_default_providers()
```

### 3. Konfiguracja

```json
// config/app_config.json
{
  "llm_providers": [
    {
      "name": "my_provider",
      "api_key_env": "MY_PROVIDER_API_KEY",
      "base_url": "https://api.myprovider.com",
      "default_model": "my-model",
      "available_models": ["my-model", "my-model-pro"]
    }
  ]
}
```

## üîê Zmienne ≈õrodowiskowe (.env)

```bash
# LLM API Keys
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
GOOGLE_API_KEY=your_google_key_here

# Logging Settings
LOG_LEVEL=INFO                    # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_DIR=logs                      # Custom log directory

# Application Settings
DEBUG=false
APP_NAME=rag_07

# Database Settings
DATABASE_PATH=databases/local.db
VECTOR_DB_PATH=databases/vector_store

# Provider Settings
DEFAULT_LLM_PROVIDER=openai
DEFAULT_VECTOR_DB_PROVIDER=faiss
```

## üß™ Testowanie

```bash
# Uruchom wszystkie testy
pytest

# Z coverage
pytest --cov=src --cov-report=html

# Konkretny test
pytest tests/test_config_manager.py -v

# Test asynchroniczny
pytest tests/test_text_processor.py::TestBasicTextProcessor::test_chunk_text
```

## üìä Wzorce projektowe zastosowane

- **Factory Pattern**: `ProviderFactory` dla tworzenia provider√≥w
- **Strategy Pattern**: Wymienne algorytmy dla r√≥≈ºnych provider√≥w
- **Adapter Pattern**: Unified interface dla r√≥≈ºnych API
- **Singleton Pattern**: `ConfigManager` jako centralny punkt konfiguracji
- **Template Method**: `BaseProvider` z wsp√≥lnƒÖ strukturƒÖ
- **Dependency Injection**: Providers wstrzykiwane przez Factory

## üîß System logowania

### Hierarchia konfiguracji (priorytet malejƒÖcy):

1. **CLI argumenty**: `--log-level DEBUG --no-log-console`
2. **Zmienne ≈õrodowiskowe**: `LOG_LEVEL=WARNING LOG_DIR=/custom/logs`
3. **Plik konfiguracyjny**: `"log_level": "INFO"`
4. **Warto≈õci domy≈õlne**: `INFO` z konsolƒÖ i plikiem

### Opcje logowania:

```bash
# Kontrola poziomu
./run.sh --log-level DEBUG command      # Szczeg√≥≈Çowe logi
./run.sh --log-level WARNING command    # Tylko ostrze≈ºenia+
./run.sh --log-level ERROR command      # Tylko b≈Çƒôdy

# Kontrola wyj≈õcia
./run.sh --no-log-console command       # Tylko do pliku
./run.sh --log-dir /custom/logs command # W≈Çasny katalog

# Kombinacje
export LOG_LEVEL=WARNING
./run.sh --log-dir /tmp/logs --no-log-console ask-with-tools "Question"
```

### Rotacja plik√≥w:

- **Lokalizacja**: `logs/rag_07.log`
- **Rotacja**: Codzienna o p√≥≈Çnocy
- **Retencja**: 3 dni (automatyczne usuwanie)
- **Format**: JSON structured logs

üìö **Szczeg√≥≈Çowa dokumentacja**: [System Logowania](docs/logging_system.md)

## üéØ Cele architektoniczne

1. **Single Responsibility**: Ka≈ºdy plik = jedna odpowiedzialno≈õƒá
2. **Elastyczno≈õƒá**: ≈Åatwe dodawanie nowych provider√≥w do arrays
3. **Centralizacja config**: Tylko ConfigManager czyta .env
4. **Async/await**: Wszystkie operacje API asynchroniczne
5. **Error Handling**: Dedicated exceptions + retry/timeout
6. **Observability**: Structured logging ka≈ºdej operacji
7. **Type Safety**: Pe≈Çne typowanie + mypy validation

## üö® Wa≈ºne uwagi

- Foldery `examples/` i `databases/` sƒÖ w .gitignore
- Tylko `ConfigManager` czyta .env, pozosta≈Çe otrzymujƒÖ gotowƒÖ konfiguracjƒô
- Ka≈ºdy provider ma jednolity interfejs + jasnƒÖ dokumentacjƒô parametr√≥w
- Brak logiki w main.py/cli.py - tylko routing do services
- Testy pokrywajƒÖ ca≈Ço≈õƒá + mockowanie zewnƒôtrznych API

## ü§ù Contributing

1. Dodaj testy dla nowej funkcjonalno≈õci
2. Uruchom `black src/ && isort src/` przed commitem
3. Sprawd≈∫ `pylint src/` i `mypy src/`
4. Dokumentuj parametry wej≈õciowe provider√≥w
5. U≈ºywaj structured logging w ka≈ºdej operacji

## üìù Zainstalowane rozszerzenia VS Code

```vscode-extensions
ms-python.python,ms-python.vscode-pylance,ms-python.black-formatter,ms-python.isort,ms-python.pylint,esbenp.prettier-vscode,dbaeumer.vscode-eslint,ms-toolsai.jupyter,github.copilot
```

---

‚ú® **Aplikacja gotowa do u≈ºycia i rozwijania!** ‚ú®
